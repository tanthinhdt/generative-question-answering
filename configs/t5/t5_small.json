{
    "model": {
        "name": "t5-small",
        "pretrained": "t5-small"
    },
    "tokenizer": {
        "truncation": true,
        "padding": "max_length",
        "return_tensors": "pt"
    },
    "dataset": {
        "dir": "data/ELI5"
    },
    "train": {
        "do_train": true,
        "include_inputs_for_metrics": true,
        "per_device_train_batch_size": 2,
        "per_device_eval_batch_size": 2,
        "auto_find_batch_size": true,
        "learning_rate": 3e-4,
        "num_train_epochs": 3,
        "max_steps": 5000,
        "weight_decay": 0.005,
        "logging_dir": "logs/t5/t5_small",
        "logging_strategy": "steps",
        "logging_steps": 100,
        "output_dir": "checkpoints/t5/t5_small",
        "overwrite_output_dir": true,
        "save_strategy": "steps",
        "save_steps": 500,
        "save_total_limit": 5,
        "run_name": "generative-question-answering",
        "report_to": "wandb",
        "gradient_checkpointing": true
    },
    "knowledge": {
        "configs_path": "configs/knowledge.json"
    }
}